{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INEPXzxL1TtP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aU8rxJ9R1Tt9",
        "outputId": "f8f77b17-195c-47f6-806a-b3caf46741aa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive # Finalized Code ||\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install googletrans==3.1.0a0\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os # Import the os module for file operations\n",
        "import csv\n",
        "import re # Import the re module for regular expressions\n",
        "from googletrans import Translator # Import the Translator class from the googletrans module\n",
        "\n",
        "\n",
        "# Replace 'Your Folder Path' with the actual path to your CSV file in Google Drive\n",
        "file_path = '/content/drive/MyDrive/Protexxa/nationwide/NationWide_LeakData.csv' # Assign the file path to a variable\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.head(20)) # Display the first few rows of the dataframe\n",
        "\n",
        "garbage_bin = pd.DataFrame()  # Create an empty DataFrame to store outliers\n",
        "\n",
        "# Create an instance of the Translator class\n",
        "translator = Translator() # Create an instance of the Translator class\n",
        "\n",
        "def translate_column_names(df, garbage_bin):\n",
        "    old_columns = df.columns.tolist() # Get the current column names as a list\n",
        "    translated_columns = [translator.translate(col, dest= 'en').text for col in old_columns] # Initialize an empty list to store translated column names\n",
        "\n",
        "    garbage_bin['Old Column Names'] = old_columns\n",
        "    df.columns = translated_columns # Assign the translated column names to the dataframe's columns\n",
        "\n",
        "    return df, garbage_bin # Return the updated dataframe\n",
        "\n",
        "# Call the translate_column_names function with the dataframe and garbage bin\n",
        "df, garbage_bin = translate_column_names(df, garbage_bin)\n",
        "\n",
        "# Save the DataFrame with translated column names to a new CSV file\n",
        "output_file_path = '/content/drive/MyDrive/Protexxa/nationwide/FinalProduct/translated_data.csv'\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Replace 'Your Folder Path' with the actual path to your CSV file in Google Drive\n",
        "file_path = '/content/drive/MyDrive/Protexxa/nationwide/FinalProduct/translated_data.csv' # Assign the file path to a variable\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "def remove_outliers_zscore(df, threshold=3):\n",
        "  \"\"\"\n",
        "  Removes outliers from a DataFrame using the Z-score method.\n",
        "\n",
        "  Args:\n",
        "    df: The DataFrame to process.\n",
        "    threshold: The Z-score threshold for identifying outliers.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the DataFrame with outliers removed and a DataFrame\n",
        "    containing the removed outliers.\n",
        "  \"\"\"\n",
        "  global garbage_bin  # Access the global garbage_bin DataFrame\n",
        "\n",
        "  for column in df.select_dtypes(include=np.number).columns:  # Iterate only numerical columns\n",
        "    z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())\n",
        "    outliers = df[z_scores > threshold]\n",
        "\n",
        "    # Store outliers in the garbage bin with column information\n",
        "    if not outliers.empty:\n",
        "      outliers['Outlier_Column'] = column\n",
        "      garbage_bin = pd.concat([garbage_bin, outliers], ignore_index=True)\n",
        "\n",
        "    df = df[z_scores <= threshold]  # Remove outliers from the original DataFrame\n",
        "\n",
        "  return df, garbage_bin\n",
        "\n",
        "# Example Usage\n",
        "df, garbage_bin = remove_outliers_zscore(df)\n",
        "\n",
        "# Now 'df' contains the DataFrame with outliers removed, and 'garbage_bin'\n",
        "# contains the removed outliers.\n",
        "print(df.head(20)) # Display the first few rows of the dataframe\n",
        "\n",
        "# Get the translated column names for 'Frame Number' and 'Engine Number'\n",
        "frame_number_col = translator.translate('Frame Number', dest='en').text\n",
        "engine_number_col = translator.translate('Engine Number', dest='en').text\n",
        "\n",
        "# Save the DataFrame with translated column names to a new CSV file\n",
        "output_file_path = '/content/drive/MyDrive/Protexxa/nationwide/FinalProduct/removedoutlier_data.csv'\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Create a list of columns to drop\n",
        "columns_to_drop = ['Unnamed: 21', 'gender', 'Birthday', 'educate', 'monthly salary', 'cell phone', 'address', 'City', 'marriage', 'Province', 'BRAND', 'car model', 'color', 'car series', 'post code', 'industry']\n",
        "\n",
        "# Iterate through the columns and move them to the garbage bin\n",
        "for column in columns_to_drop:\n",
        "    if column in df.columns:\n",
        "        # Store the entire column in the garbage bin\n",
        "        garbage_bin[column] = df[column]\n",
        "        df = df.drop(column, axis=1)\n",
        "    else:\n",
        "        print(f\"Warning: Column '{column}' not found in DataFrame.\")\n",
        "\n",
        "def handle_invalid_values(df, garbage_bin):\n",
        "  invalid_values = df.isnull().any(axis=1)  # Identify rows with invalid values\n",
        "\n",
        "  # Store rows with invalid values in the garbage bin\n",
        "  garbage_bin = pd.concat([garbage_bin, df[invalid_values]], ignore_index=True)\n",
        "\n",
        "  df = df.dropna()  # Remove rows with invalid values\n",
        "  return df, garbage_bin\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('/content/drive/MyDrive/Protexxa/nationwide/FinalProduct/NationWideClean.csv', index=False)\n",
        "\n",
        "# Save the garbage bin DataFrame to a CSV file\n",
        "garbage_bin.to_csv('/content/drive/MyDrive/Protexxa/nationwide/Garbage/finalgarbage3.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbWzzuyLMBlm"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
